# ğŸ§© local-data-infra

`repositÃ³rio de estudo e testes de IaC`

`em desenvolvimento`

Infraestrutura modular, reprodutÃ­vel e portÃ¡til para projetos de dados em ambiente local, construÃ­da com Terraform, Docker e Kubernetes (Helm).


## âš™ï¸ Stack Principal
- **Airflow** â†’ OrquestraÃ§Ã£o de pipelines
- **DBT** â†’ TransformaÃ§Ãµes SQL e modelagem
- **PostgreSQL 16** â†’ Data Warehouse relacional
- **Terraform + Kind** â†’ Cluster Kubernetes local
- **Helm + Helmfile** â†’ Gerenciamento modular dos serviÃ§os

---

## ğŸš€ Guia de InicializaÃ§Ã£o

### PrÃ©-requisitos

Certifique-se de ter as seguintes ferramentas instaladas:
- [Docker](https://docs.docker.com/get-docker/) e [Docker Compose](https://docs.docker.com/compose/install/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)
- [Terraform](https://www.terraform.io/downloads)
- [Helm](https://helm.sh/docs/intro/install/) e [Helmfile](https://helmfile.readthedocs.io/en/latest/#installation)

### âš™ï¸ 1ï¸âƒ£ Subir ambiente Kubernetes (Kind)

Este passo cria um cluster Kubernetes local chamado `data-platform` usando o Kind.

```bash
# 1. Navegue para o diretÃ³rio do Terraform
cd infra/terraform

# 2. Inicialize o Terraform
terraform init

# 3. Aplique a configuraÃ§Ã£o para criar o cluster Kind
terraform apply -auto-approve
```

### âš™ï¸ 2ï¸âƒ£ Implantar os serviÃ§os (Helmfile)

Com o cluster Kind ativo, implante os serviÃ§os de dados (Postgres, Airflow, DBT) no namespace `data`.

```bash
# 1. Retorne para o diretÃ³rio raiz do projeto
cd ../..

# 2. Implante os serviÃ§os usando Helmfile
# O Helmfile garantirÃ¡ que o namespace 'data' seja criado e que o Postgres suba antes do Airflow.
helmfile -f infra/k8s/helmfile.yaml apply
```

**Acessos (Kubernetes):**
- **Airflow UI:** `http://localhost:30080` (UsuÃ¡rio: `airflow`, Senha: `airflow`)
- **Postgres:** Acesso interno ao cluster via `postgres.data.svc.cluster.local:5432`

### âš™ï¸ 3ï¸âƒ£ Criar banco para novo projeto

Cada projeto que usar essa infra terÃ¡ **seu prÃ³prio banco e usuÃ¡rio** dentro do mesmo Postgres.

Use o script `create_project_db.sh`, que funciona tanto para o ambiente Docker Compose quanto para o Kubernetes.

```bash
bash scripts/create_project_db.sh <nome_projeto> <usuario> <senha>
```

Exemplo:
```bash
bash scripts/create_project_db.sh retail retail_user retail_pass
```

SaÃ­da esperada:
```arduino
ğŸš€ Criando banco e usuÃ¡rio para o projeto: retail
ğŸ³ Ambiente Docker detectado. (ou â˜¸ï¸ Ambiente Kubernetes detectado.)
âœ… Banco e usuÃ¡rio criados com sucesso!
ğŸ”— String de conexÃ£o (Docker Compose):
   postgresql://retail_user:retail_pass@postgres:5432/db_retail
ğŸ”— String de conexÃ£o (Kubernetes):
   postgresql://retail_user:retail_pass@postgres.data.svc.cluster.local:5432/db_retail
```

### âš™ï¸ 4ï¸âƒ£ Uso com outros repositÃ³rios (DBT)

Para usar o DBT em um repositÃ³rio externo (`retail-pipeline`), configure o arquivo `profiles.yml` com a string de conexÃ£o Kubernetes.

Consulte o arquivo de exemplo `dbt_project/profiles.yml.example` para a configuraÃ§Ã£o correta.

### âš™ï¸ 5ï¸âƒ£ Rodar ambiente local via Docker Compose (Alternativa)

Para um ambiente de desenvolvimento mais leve, sem a necessidade do Kubernetes, use o Docker Compose.

```bash
# 1. Retorne para o diretÃ³rio raiz do projeto
cd infra/terraform/..

# 2. Suba os serviÃ§os em background
docker-compose -f docker/docker-compose.yaml up -d
```

**Acessos (Docker Compose):**
- **Airflow UI:** `http://localhost:8080` (UsuÃ¡rio: `airflow`, Senha: `airflow`)
- **Postgres:** `localhost:5432` (user: `dw_user`, pass: `dw_pass`)

### âš™ï¸ 6ï¸âƒ£ Limpeza

Para derrubar os ambientes:

**Kubernetes (Kind):**
```bash
cd infra/terraform
terraform destroy -auto-approve
```

**Docker Compose:**
```bash
docker-compose -f docker/docker-compose.yaml down -v
```